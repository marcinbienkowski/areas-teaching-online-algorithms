\documentclass[a4paper,11pt]{scrartcl}
\input{macros}
\begin{document}

\newtheorem{theorem}{Twierdzenie}
\newtheorem{lemma}{Lemat}

\newcommand{\MTM}{\textsc{Mtm}}
\newcommand{\PMTM}{P_\mathrm{MTM}}
\newcommand{\PMTLM}{P_\mathrm{MTLM}}
\newcommand{\POPT}{P_\mathrm{OPT}}
\newcommand{\PCNT}{P_\mathrm{COUNT}}
\newcommand{\MTLM}{\textsc{Mtlm}}
\newcommand{\EDGE}{\textsc{Edge}}

\section{Przenoszenie plików}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Algorytm Move-To-Min}

Rozważmy teraz następujący algorytm deterministyczny {\sc Move-To-Min} ($\MTM$). 
Algorytm ten dzieli całą sekwencję na fazy długości $D$. W każdej fazie algorytm przebywa w jednym wierzchołku, który
oznaczamy $\PMTM$ a pod koniec fazy przenosi się do tzw.~{\em centrum grawitacji}, $v^*$. Wierzchołek $v^*$ jest wierzchołkiem
w którym byłoby najlepiej przebywać w danej fazie, tj.~jest wirzchołkiem minimalizującym sumę $\sum_{i=1}^D d(v^*, \sigma_i)$.

\begin{theorem}
\label{thm:mtm-competitive}
Algorytm $\MTM$ jest $7$-konkurencyjny.
\end{theorem}

\myfigure{mtm}{Ilustracja algorytmu $\MTM$ w jednej fazie}{\includegraphics{pict/mtm}}

Aby pokazać powyższe twierdzenie, zdefiniujemy funkcję potencjału równą $2 \cdot D \cdot d(\PMTM, \POPT)$ i 
pokażemy że zamortyzowany koszt w pojedynczej fazie $f$ jest ograniczony. 

Poniżej koncentrujemy się na pojedynczej fazie $f$. Numerujemy kroki w tej fazie od $1$ do $D$. 
Wprowadzimy dodatkowe oznaczenie, które zilustrowane zostało na Rysunku 
\ref{fig:mtm}. Mianowicie oznaczamy wierzchołek w którym $\OPT$ ma plik na początku kroku $j$ przez $a_{j-1}$,
a wierzchołek w którym $\OPT$ ma plik na końcu kroku $j$ przez~$a_j$. W szczególności $a_0$ i $a_D$ są wierzchołkami,
w których $\OPT$ ma plik odpowiednio na początku i końcu fazy.

Na początku pokażemy następujący pomocniczy lemat.
Mówi on, że dolnym ograniczeniem na koszt algorytmu optymalnego jest koszt algorytmu, który 
całą fazę spędzi w dowolnym wierzchołku $a_\ell$. 

\begin{lemma}
\label{lem:page_migration_opt_lower}
Dla dowolnej fazy $f$ i dowolnego kroku $0 \leq \ell \leq D$, zachodzi $\OPT(f) \geq \sum_{i=1}^D d(a_\ell, \sigma_i)$.
\end{lemma}

\begin{proof}
Zgodnie z oznaczeniami z rysunku koszt algorytmu optymalnego wynosi $\sum_{i=1}^D (d(a_{i-1}, \sigma_i) + 
D \cdot d(a_{i-1},a_i))$. W powyższej sumie każda z odległości pomiędzy kolejnymi $a_i$ jest liczona $D$ razy. 
Z nierówności trójkąta otrzymujemy, że 
\begin{align*}
\OPT(f) = &\; \sum_{i=1}^D \left(d(a_{i-1}, \sigma_i) + D \cdot d(a_{i-1},a_i)\right) \\
		\geq &\; \sum_{i=1}^D \left(d(a_{i-1}, \sigma_i) + d(a_{i-1},a_\ell)\right) \\
		\geq &\; \sum_{i=1}^D d(a_\ell,\sigma_i) \enspace. \qedhere 
\end{align*}
\end{proof}

Podzielmy koszt $\MTM(f)$ na dwie składowe: $\MTM^\mathrm{REQ}(f)$ jest kosztem obsługi żadań 
w fazie~$f$, a $\MTM^\mathrm{MOVE}(f)$ jest kosztem przenosin pliku do wierzchołka $v^*$. 
Dodatkowo definiujemy $\Phi_\mathrm{B}(f)$ i $\Phi_\mathrm{F}(f)$ jako potencjał odpowiednio na początku i końcu fazy $f$.
Należy zatem pokazać, że prawdziwe jest następujące stwierdzenie.

\begin{lemma}
\label{lem:mtm_upper_1}
Dla dowolnej fazy $f$ zachodzi 
\[
	\MTM^\mathrm{REQ}(f) + \MTM^\mathrm{MOVE}(f) 
		+ \Phi_\mathrm{F}(f) \leq \Phi_\mathrm{B}(f) + 7 \cdot \OPT(f).
\]
\end{lemma}

\begin{proof}
Z warunku trójkąta oraz Lematu~\ref{lem:page_migration_opt_lower} wynikają następujące nierówności:
\begin{align}
\label{eq:mtm_bound_1}
	\MTM^\mathrm{REQ}(f) = &\; \sum_{i=1}^D d(\PMTM,\sigma_i) 
			\leq \sum_{i=1}^D \left( d(\PMTM, a_0) + d(a_0, \sigma_i) \right) \\
\nonumber
			\leq &\; D \cdot d(\PMTM,a_0) + \sum_{i=1}^D (a_0, \sigma_i) 
			\leq \Phi_B / 2 + \OPT(f)  \\
\bigskip
\label{eq:mtm_bound_2}
	\MTM^\mathrm{MOVE}(f) = &\; D \cdot d(\PMTM, v^*) 
			\leq D \cdot d(\PMTM, a_0) + D \cdot d(a_0, v^*) \\
\nonumber
			\leq &\; \Phi_B / 2 + D \cdot d(a_0,v^*) \\
\bigskip
\label{eq:mtm_bound_3}
	\Phi_F = &\; 2 \cdot D \cdot d(a_D, v^*) 
\end{align}
Wystarczy zatem ograniczyć $d(a_\ell,v^*)$ dla $0 \leq \ell \leq D$.
\begin{align*}
D \cdot d(a_\ell, v^*) \; 
			= &\;  \sum_{i=1}^D d(a_\ell,v^*) 
			\leq \sum_{i=1}^D d(a_\ell,\sigma_i) + \sum_{i=1}^D d(v^*,\sigma_i)
			\enspace.
\intertext{Ponieważ $v^*$ został wybrany jako wierzchołek który minimalizuje sumaryczną odległość 
od żądań w całej fazie, otrzymujemy:}
D \cdot d(a_\ell, v^*) \; \leq & \;2 \cdot \sum _{i=1}^D d(a_\ell,\sigma_i) \leq 2 \cdot \OPT(f)
\end{align*}
Podstawiając to ograniczenie do nierówności (\ref{eq:mtm_bound_1}), 
(\ref{eq:mtm_bound_2}) i (\ref{eq:mtm_bound_3}), otrzymujemy tezę lematu.
\end{proof}

\begin{proof}[Dowód twierdzenia \ref{thm:mtm-competitive}]
Weźmy dowolną sekwencję $\sigma$ i jej podział na fazy $\sigma = (f_1, f_2, \ldots, f_k, f_{k+1})$. 
Ostatnia faza ma być może mniej niż $D$ kroków. Zauważmy, że zamortyzowany koszt w dowolnej z faz może zostać ograniczony
przez funkcję zależną $D$ i średnicy grafu $G$. Oznaczmy to ograniczenie przez $\beta$.
Otrzymujemy wtedy
\begin{align*}
\MTM(\sigma) + \Delta\Phi(\sigma) 
	= & \; \sum_{i=1}^k\left( \MTM(f_i) + \Delta\Phi(f_i) \right) + 
			 \MTM(f_{k+1}) + \Delta\Phi(f_{k+1}) \\
	\leq &\; \sum_{i=1}^k \left( 7 \cdot \OPT(f_i) \right) + \beta \\
	\leq &\; 7 \cdot \OPT(\sigma) + \beta
\end{align*}
Ponieważ $\Delta\Phi(\sigma)$ jest nieujemne otrzymujemy 
$\MTM(\sigma) \leq 7 \cdot \OPT(\sigma) + \beta$, co kończy dowód konkurencyjności algorytmu $\MTM$.
\end{proof}

\subsubsection{Algorytm Move-To-Local-Min}

Zauważmy, że $\MTM$ kiepsko radzi sobie z sytuacją, w której jest wiele minimów będących kandydatami na $v^*$. 
Wtedy $\MTM$ wybiera jedno z nich, podczas gdy mógłby wybierać najbliższe. Warto również wybrać wierzchołek
prawie minimalny jeśli jest on znacznie bliżej aktualnej pozycji pliku niż globalne minimum.
Prowadzi nas to do algorytmu \textsc{Move-To-Local-Min} ($\MTLM$), który różni się od $\MTM$ tylko wyborem $v^*$.
$\MTLM$ wybiera na  $v^*$ ten wierzchołek $v$, który minimalizuje sumę 
$2 \cdot \sum_{i=1}^D d(v,\sigma_i) + D \cdot d(\PMTLM,v)$. 

\begin{theorem}
$\MTLM$ jest $5$-konkurencyjny.
\end{theorem}

\begin{proof}
Wystarczy pokazać odpowiednik Lematu~\ref{lem:mtm_upper_1}, reszta dowodu jest identyczna jak w przypadku 
algorytmu $\MTM$. Ograniczenie na $\MTLM^\mathrm{REQ}(f)$ jest identyczne, tj.
\begin{align*}
	\MTLM^\mathrm{REQ}(f) \;\leq&\; \Phi_\mathrm{B}/2 + \OPT(f) \enspace. \\
\intertext{Z kolei}
	\MTLM^\mathrm{MOVE}(f) + \Phi_\mathrm{F} \;
	\leq &\; D \cdot d (\PMTLM,v^*) + 2 \cdot D \cdot d(a_D, v^*) \\
	\leq &\; D \cdot d (\PMTLM,v^*) + 2 \cdot \sum_{i=1}^D d(v^*, \sigma_i) + 2 \cdot \sum_{i=1}^D d(a_D, \sigma_i) \\
	\leq &\; D \cdot d (\PMTLM,v^*) + 2 \cdot \sum_{i=1}^D d(v^*, \sigma_i) + 2 \cdot \OPT(f)
\end{align*}
Z minimalności $v^*$ w pierwszych dwóch składnikach powyżej możemy zamienić $v^*$ na $a_0$ otrzymując
\begin{align*}
	\MTLM^\mathrm{MOVE}(f) + \Phi_\mathrm{F} \;
	\leq &\; D \cdot d (\PMTLM,a_0) + 2 \cdot \sum_{i=1}^D d(a_0, \sigma_i) + 2 \cdot \OPT(f) \\
	\leq &\; \Phi_\mathrm{B}/2 + 4 \cdot \OPT(f) \enspace.
\qedhere
\end{align*}
\end{proof}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Randomizacja przeciwko adwersarzowi nieświadomememu}

Jeśli przyjrzymy się algorytmowi $\MTM$ zauważymy, że dzieli on sekwencję wejściową na fazy po $D$ kroków i 
przenosi plik na końcu takiej fazy. Gdybyśmy zaczęli fazę nie na początku sekwencji wejściowej, lecz po paru krokach
nie zmieniłoby to analizy algorytmu. Nie pomogło (ani też nie przeszkodziłoby) nam to przeciwko 
adwersarzowi adaptującemu się. 
Natomiast może to pomóc przeciwko adwersarzowi oblivious, który nie wie gdzie dana faza się kończy czy zaczyna.

Te obserwacje są podstawą algorytmu $\CNT_k$. Algorytm ten przechowuje globalny licznik $C$, który przyjmuje wartości z zakresu
$[0,k]$. Jest on inicjowany wylosowaną (z rozkładem jednostajnym) liczbą naturalną z przedziału $[1,k]$.
Przy dowolnym odwołaniu do pliku, $C$ jest zmniejszane o $1$. Jeśli w efekcie $C = 0$, plik jest 
przesuwany do wierzchołka,
który właśnie zażądał do niej dostępu, a następnie licznikowi $C$ jest przypisywane~$k$.

\begin{lemma}
Algorytm $\CNT_k$ jest $\max\{2 + \frac{2 d}{k}, 1+\frac{k+1}{2d} \}$-konkurencyjny przeciwko adwersarzowi oblivious.
\end{lemma}

\begin{proof}
Definiujemy funkcję potencjału 
równą 
\[
	\Phi = (D + C) \cdot d(\PCNT,\POPT) \enspace.
\]
Dzielimy każdy krok na dwa etapy; pokażemy, że zamortyzowany koszt algorytmu
w każdym etapie jest ograniczony.
\begin{description}
\item[\textnormal{\em Etap 1.}] 
	Przyjrzyjmy się najpierw zamortyzowanemu kosztowi obsługi żądania w $\sigma_t$. 
	Oczywiście \[ \CNT_k^\mathrm{odwołanie} = d(\PCNT, \sigma_t) \enspace. \]
	Za obsługę tego żądania płaci spadek potencjału (związany ze spadkiem
	wartości licznika), tj.~$\Delta\Phi = -d(\PCNT,\POPT)$. Otrzymujemy 
	\[ \CNT_k^\mathrm{odwołanie} + \Delta\Phi \leq d(\POPT,\sigma_t) = \OPT \enspace. \]

	Dodatkowo, z prawdopodobieństwem $\frac{1}{k}$, po obsłudze żądania zachodzi $C = 0$. 
	Z takim prawdopodobieństwem
	następuje przeniesienie pliku, którego koszt jest równy $D \cdot d(\PCNT, \sigma_t)$ 
	a związana z nią zmiana potencjału to $\Delta\Phi = (D+k) \cdot d(\sigma_t, \POPT) - D \cdot d(\PCNT, \POPT)$.
	Otrzymujemy zatem, że 
	\begin{align*}
		 \E[\CNT_k^\mathrm{przenosiny} + \Delta\Phi] 
		 	= & \; \frac{1}{k} \cdot \left[ 
				D \cdot d(\PCNT, \sigma_t) - D \cdot d(\PCNT, \POPT)  + (D+k) \cdot d(\sigma_t, \POPT)
			\right]  \\
			\leq & \; \frac{1}{k} \cdot \left[ D \cdot d(\POPT,\sigma_t) + (D+k) \cdot d(\sigma_t, \POPT) \right] \\
			= & \; \frac{2 D + k}{k} \cdot \OPT \enspace.
	\intertext{Sumując otrzymujemy}
		\E[\CNT_k + \Delta\Phi] \leq & \; \left(2 + \frac{2 D}{k}\right) \cdot \OPT \enspace. 
	\end{align*}

\item[\textnormal{\em Etap 2.}] 
	Załóżmy teraz, że $\OPT$ przenosi plik z wierzchołka $\POPT$ do $\POPT'$. Wtedy zmiana potencjału to 
	$(D+C) \cdot [d(\PCNT, \POPT') - d(\PCNT, \POPT)] \leq (D+C) \cdot d(\POPT, \POPT')$.
	Zauważmy teraz, że wartość oczekiwana licznika $C$ wynosi $\frac{k+1}{2}$, a zatem oczekiwana zmiana potencjału to
	\begin{align*}
		\E[\Delta\Phi] = &\; \left(D + \frac{k+1}{2}\right) \cdot d(\POPT,\POPT')  \\
			= &\; \left(1 + \frac{k+1}{2 D}\right) \cdot \OPT \enspace.
	\end{align*}

\end{description}
Porównując wyniki w dwóch etapach otrzymujemy tezę lematu.
\end{proof}

Poniższe twierdzenie pozostawiamy bez dowodu jako proste ćwiczenie rachunkowe.

\begin{theorem}
Istnieje taki wybór $k$ (jako funkcji $D$), że dla $D$ dążącego do nieskończoności, konkurenyjność algorytmu $\CNT_k$
zbiega do $(1 + \phi)$, gdzie $\phi = \frac{1+\sqrt{5}}{2}$ jest złotym podziałem. 
\end{theorem}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Optymalny algorytm dla dwóch wierzchołków}

W tej części przedstawimy pewną technikę nazywaną funkcją pracy ({\em work function}), którą
wykorzystamy do konstrukcji optymalnego algorytmu zrandomizowanego dla grafu dwuwierzchołkowego.

\subsubsection{Opis rozkładowy algorytmu}

Okazuje się, że do prezentacji tej techniki, wygodniej jest korzystać z innego
opisu algorytmu, opisu rozkładowego.  Mianowicie zamiast określać, że algorytm
przenosi plik z pewnym prawdopodobieństwem, będziemy definiować algorytm
przez jego rozkład prawdopodobieństwa nad możliwymi stanami.  W przypadku
problemu przenoszenia pliku, w kroku $t$ będziemy określać jaki jest rozkład
prawdopodobieństwa pozycji pliku. 

W naszych rozważaniach ograniczymy się do grafu dwuwierzchołkowego, którego
wierzchołki oznaczymy przez $a$ i $b$.  Bez straty ogólności możemy założyć, że
odległość między $a$ i $b$ wynosi $1$.  W każdym kroku będziemy określać
rozkład $\mu$; taki rozkład oznacza, że algorytm ma plik w $a$ z
prawdopodobieństwem $\mu(a)$ a w $b$ z prawdopodobieństwem $\mu(b) = 1 -
\mu(a)$. Oczywiście, żeby taki opis miał sens, adwersarz musi być nieświadomy.

Zauważmy, że jeśli algorytm ma w kroku $t$ rozkład $\mu$, a odwołanie jest w
wierzchołku $a$, to w wartości oczekiwanej algorytm płaci za to odwołanie
$\mu(a) \cdot 0 + \mu(b) \cdot 1 = \mu(b)$.  Musimy teraz pokazać, że przejście
między dwoma rozkładami da się wykonać i określić jaki jest koszt takiego
przejścia.

\begin{lemma}
Dla grafu dwuwierzchołkowego $(a,b)$ z $d(a,b) = 1$ i 
dwóch rozkładów prawdopodobieństwa $\mu$ i $\mu'$, koszt przejścia pomiędzy 
nimi wynosi $D \cdot |\mu(a) - \mu'(a)|$.
\end{lemma}

\begin{proof}
Załóżmy, że mamy zrandomizowany algorytm, który po przeczytaniu pewnego
fragmentu wejścia ma plik w wierzchołku $a$ z prawdopodobieństwem $\mu(a)$ i
w wierzchołku $b$ z prawdopodobieństwem $\mu(b)$. 

Jeśli $\mu'(a) = \mu(a)$, to algorytm nie przenosi pliku, związany z tym koszt
jest równy zero i teza twierdzenia jest spełniona. W przeciwnym przypadku, bez
straty ogólności możemy założyć, że $\mu(a) > \mu'(a)$.  Wtedy strategia dla
algorytmu jest następująca:
\begin{itemize}
\item jeśli plik jest w $b$, nic nie rób,
\item jeśli plik jest w $a$, przenieś ją do $b$ z prawdopodobieństwem $p = \frac{\mu(a) - \mu'(a)}{\mu(a)}$ .
\end{itemize}
Zauważmy, że prawdopodobieństwo że algorytm skończy ze plikiem w wierzchołku $a$
wynosi $\mu(a) \cdot (1 - p) = \mu'(a)$, a więc otrzymaliśmy zadany rozkład
prawdopodobieństwa.  Oczekiwany koszt, jaki poniósł nasz algorytm wynosi $p
\cdot \mu(a) \cdot D = D \cdot (\mu(a) - \mu'(a))$.  
\end{proof}

\subsubsection{Funkcje pracy i algorytm EDGE}

Funkcje pracy ({\em work functions}) są techniką, która często pozwala na konstrukcję
algorytmów online osiągających optymalne współczynniki. Idea polega na tym, że w każdym 
kroku $t$ dla dowolnego stanu $x$ obliczamy $w_t(x)$, koszt optymalnego rozwiązania widzianej
do tej pory sekwencji, które kończy działanie w stanie $x$. Funkcję $w_t$ nazywamy funkcją pracy 
w kroku $t$; indeks $t$ będziemy zawyczaj pomijać. 

Oczywistą własnością funkcji $w$ jest: $\OPT(\sigma) = \min_x w_{|\sigma|}(x)$. 
Warto zwrócić uwagę, że choć koszt optymalnego rozwiązania na dowolnym prefiksie wejścia o długości 
$\ell$ jest równy $\min w_\ell(x)$, to optymalny algorytm 
nie musi być (często nie może być) optymalny na każdym z prefiksów.
Jednak w analizie algorytmów możemy (i będziemy) zakładać, że koszt $\OPT$ w danym kroku $t$
jest równy $\min_x w_t(x) - \min_x w_{t-1}(x)$. 

Zależność między funkcją pracy a kosztem optimum prowadzi do pomysłu, że
algorytm powinien przebywać możliwie najczęściej w stanie, który minimalizuje funkcję $w$. 
Jeśli jednak tak zdefiniujemy algorytm, to zazwyczaj adwersarz jest w stanie 
wygenerować sekwencję, w której to minimum zmienia się często i algorytm płaci dużo za zmianę 
stanów.

Przy algorytmach zrandomizowanych można sobie z tym poradzić, zmieniając stan z
małym prawdopodobieństwem. Ta idea jest podstawą algorytmu $\EDGE$. Zdefiniujmy
przesunięcie $g := w(b) - w(a)$.  Zauważmy, że jeśli algorytm optymalny może
skończyć z pewnym kosztem $w(a)$ w wierzchołku $a$, to może skończyć z kosztem
co najwyżej $w(a)+D$ w wierzchołku $b$ (może wziąć strategię kończącą w $a$ i
na samym końcu przenieść plik do $b$). Dlatego też $w(b) \leq w(a) + D$
i zatem z symetrii wynika, że $g \in [-D,D]$. 

Algorytm $\EDGE$ ustala pewien rozkład prawdopodobieństwa na podstawie wartości $g$,
mianowicie
\begin{align}
	\mu(a) := \frac{D+g}{2D}\enspace, & & \mu(b) := \frac{D-g}{2D} \enspace.
\end{align}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{theorem}
Algorytm $\EDGE$ jest ściśle $(2+\frac{1}{2D})$-konkurencyjny przeciwko adwersarzowi nieświadomememu
na grafach dwuwierzchołkowych.
\end{theorem}

\begin{proof}
Dowód jest tak naprawdę klasyczną analizą zamortyzowaną, choć nie napiszemy bezpośrednio 
funkcji potencjału.
Po pierwsze obliczymy jakie są koszty $\EDGE$ i $\OPT$ w zależności od zmiany $g$.
Po pierwsze zauważmy, że jeśli $g$ się zmienia, to zmienia się o $1$ i wtedy 
związany z tym oczekiwany koszt przenosin pliku to $D \cdot \frac{1}{2D} = \frac{1}{2}$.

Bez straty ogólności, możemy założyć, że $g$ jest nieujemne, czyli $w(b) \geq w(a)$. 
Rozpatrzmy parę przypadków:

\begin{enumerate}
\item Jeśli odwołanie jest w $a$ i $g < D$, to $g$ zwiększa się o $1$. W efekcie
	$\EDGE$ płaci $\mu(b)$ za żądanie i $1/2$ za przenosiny pliku, zaś $\OPT$ nie płaci nic.
\item Jeśli odwołanie jest w $a$ i $g = D$, to $g$ nie zmienia się.
	Zauważmy, że w takim przypadku $\mu(a) = 1$ i zatem $\EDGE$ nie płaci nic. 
	$\OPT$ również nic nie płaci.
\item Jeśli odwołanie jest w $b$ i $g = 0$, to jest tak samo jak gdyby odwołanie było w $a$ 
	(patrz przypadek 1).
\item Jeśli odwołanie jest w $b$ i $g > 0$, to $g$ zmniejsza się o $1$. W efekcie 
	$\EDGE$ płaci $\mu(a)$ za żądanie i $1/2$ za przenosiny pliku, zaś $\OPT$ płaci $1$.
\end{enumerate}

Zobaczmy teraz jak wyglądają koszty w zależności od zmiany $|g|$:
\begin{enumerate}
\item Jeśli $|g|$ się nie zmienia, to nic się nie dzieje. 
\item Jeśli $|g|$ rośnie o $1$, to $\E[\EDGE] = 1 - \frac{g}{2D}$, a $\OPT = 0$.
\item Jeśli $|g|$ maleje o $1$, to $\E[\EDGE] = 1 + \frac{g}{2D}$, a $\OPT = 1$.
\end{enumerate}

Zauważmy, że trudny jest przypadek 2, bo wtedy $\OPT = 0$. 
Zróbmy zatem następujący eksperyment myślowy: W momencie kiedy $|g|$ się zmniejsza 
(np. z $x+1$ do $x$) oprócz płacenia za faktyczny oczekiwany koszt $\EDGE$ odłożmy dodatkowo
kwotę, która zapewni nam, że będziemy mogli zapłacić za zwiększenie $|g|$ od $x$ do $x+1$. 
Oznacza to, że zamortyzowany koszt w momencie zmniejszenia się $|g|$ to 
$(1 - \frac{x+1}{2D}) + (1+\frac{x}{2D}) = 2 + \frac{1}{2D}$, natomiast zamortyzowany 
koszt w momencie zwiększenia się $|g|$ to $0$. 
Zatem konkurencyjność wynosi $2 + \frac{1}{2D}$. 

Zauważmy dodatkowo, że ponieważ zaczynamy od maksymalnej możliwej wartości $|g|$, tj $D$,
konkurencyjność ta jest ścisła.  
%
%Zdefiniujmy następującą funkcję potencjału 
%\[ \Phi = \sum_{i=1}^{D-|g|} \left( \frac{1}{2} + \frac{i}{2D} \right) \enspace. \]
%Pokażemy, że w każdym kroku zachodzi 
%\begin{equation}
%\label{eq:edge_competitive}
%\E[\EDGE] + \E[\Delta\Phi] \;\leq\; \left(2+\frac{1}{2D} \right)
%  \cdot \OPT \enspace.
%\end{equation}
%Bez straty ogólności możemy założyć, że $g \geq 0$. 
%Na początku zauważmy, że zmiana $g$ o jeden (zwiększenie lub zmniejszenie) powoduje przesunięcie się 
%masy $\frac{1}{2D}$ prawdopodobieństwa między wierzchołkami, co generuje koszt równy $D \cdot \frac{1}{2D}
%= \frac{1}{2}$.
%
%Idea dowodu jest następująca. Jeśli $g$ nie zmienia się, to zarówno algorytm $\EDGE$, jak i algorytm optymalny 
%nie ponoszą kosztu. Jeśli $g$ zmienia się, to koszt (niezamortyzowany) algorytmu jest --- z dokładnością 
%do stałego czynnika --- taki sam.
%Zatem kiedy wartość bezwzględna $g$ się zmniejsza, wtedy z definicji funkcji pracy $\OPT$ ponosi koszt $1$.
%W przeciwnym przypadku, co prawda $\OPT$ może nic nie płacić, ale potencjał zmniejsza się 
%dokładnie o tyle, ile wynosi koszt algorytmu. Formalny dowód powyższych intuicji wymaga rozpatrzenia 
%dwóch przypadków.
%\begin{description}
%\item[\textnormal{\em Przypadek 1.}] Wierzchołek $a$ żąda dostępu do pliku.
%	Jeśli na początku ruchu $g = D$, to nierówność~\ref{eq:edge_competitive} jest trywialnie spełniona, gdyż
%	przesunięcie $g$ się nie zmienia ($g$ nie może być większe od $D$). Wtedy 
%	$\EDGE = \Delta\Phi = \OPT = 0$.
%
%	Załóżmy zatem, że $g \leq D - 1$. Zatem nowa wartość przesunięcia to $g' = g+1$. 
%	Koszt związany z obsługą żądania to $\mu(b)$, a koszt przeniesienia pliku to $1/2$.
%	Zatem 
%	\[
%		\E[\EDGE] + \E[\Delta\Phi] = \frac{D-g}{2D} + \frac{1}{2} - \left( \frac{1}{2} + \frac{D-g}{2D} 
%		\right) = 0 = \OPT \enspace.
%	\]
%	
%\item[\textnormal{\em Przypadek 2.}] Wierzchołek $b$ żąda dostępu do pliku.
%	Przypadek $g = 0$ został rozpatrzony w poprzednim punkcie (wystarczy zamienić rolami $a$ i $b$).
%	Możemy zatem założyć, że $g \geq 1$. Wtedy nowa wartość przesunięcia to $g' = g-1$ a koszt 
%	$\OPT$ rośnie o $1$.
%	Analogicznie jak w poprzednim punkcie $\E[\EDGE]= \mu(a) + \frac{1}{2}$. Zatem 
%	\[
%		\E[\EDGE] + \E[\Delta\Phi] = \frac{D+g}{2D} + \frac{1}{2} + \left(\frac{1}{2} +
%		\frac{D-g+1}{2D} \right) = 
%		1 + \frac{2D+1}{2D} = \left(2 + \frac{1}{2 D}\right) \cdot \OPT \enspace.
%	\]
%\end{description}
%Stąd wynika, że w obu przypadkach nierówność \ref{eq:edge_competitive} jest spełniona.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\end{document}
